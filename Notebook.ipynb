{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notebook.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oi7QfD61CJc_"
      },
      "source": [
        "## Przygotowanie\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVd8ptoFJZw5"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "keras = tf.keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeEbf8l9J6TN"
      },
      "source": [
        "def plot_series(time, series, format=\"-\", start=0, end=None, label=None):\n",
        "    plt.plot(time[start:end], series[start:end], format, label=label)\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Value\")\n",
        "    if label:\n",
        "        plt.legend(fontsize=14)\n",
        "    plt.grid(True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjKYzZIDFvsz"
      },
      "source": [
        "#Występowanie\n",
        "Szeregi czasowe występują dosłownie w każdej dziedzinie życia. Ich zastosowanie można łatwo dostrzec m.in w prognozach pogody, na giełdzie, w historycznych danych, pomiarach.\n",
        "\n",
        "#Szereg czasowy\n",
        "Szeregiem czasowym nazywamy uporządkowaną sekwencję, w której dane ułożone są sekwencyjnie, a kluczem określającym ich położenie jest czas.\n",
        "W zależności od wartości określanych przez encjęw danym punkcie w czasie, dane możemy podzielić na:\n",
        "- jednowymiarowe (jedna wartość w jednym punkcie)\n",
        "- wielowymiarowe (wiele wartości w jednym punkcie)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ewKYZrLLmKG"
      },
      "source": [
        "#Przykładowy zbiór danych jednowymiarowych.\n",
        "Zbiór szeregów przedstawiających ilość sprzedanych szamponów na przestrzeni 3 lat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgw8e11xHs2d"
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/Mervolt/TimeSeriesTutorial/master/shampoo.csv\"\n",
        "\n",
        "shampoo_dataset = pd.read_csv(url, error_bad_lines=False)\n",
        "print(shampoo_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TGwsFQ1JyyY"
      },
      "source": [
        "time, values = shampoo_dataset[\"Month\"], shampoo_dataset[\"Sales\"]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(time, values, label = False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-E77Z6rMAKU"
      },
      "source": [
        "#Przykładowy zbiór danych wielowymiarowych\n",
        "Zbiór szeregów przedstawiających obserwacje ilości ozonu przez 6 lat\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQ4gPiCnNGCS"
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/Mervolt/TimeSeriesTutorial/master/ozone.csv\"\n",
        "\n",
        "ozone_dataset = pd.read_csv(url)\n",
        "print(ozone_dataset)\n",
        "\n",
        "time, values = ozone_dataset[\"Time\"], ozone_dataset[ozone_dataset.columns[2:6]]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(time, values[\"2\"], label = False)\n",
        "plot_series(time, values[\"3\"], label = False)\n",
        "plot_series(time, values[\"4\"], label = False)\n",
        "plot_series(time, values[\"5\"], label = False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4gnkJEZHH-z"
      },
      "source": [
        "#Wspólne cechy szeregów\n",
        "\n",
        "Wiele szeregów czasowych posiada takie właściwości jak:\n",
        "- trend (np. monotoniczny wzrost lub spadek)\n",
        "- sezonowość, którą można zaobserwować jako okres na wykresie (np. ilość turystów w zależności od miesiąca pokazywać będzie największe wartości w okresie letnim)\n",
        "- szum, czyli zakłócenia, drobne błędy wartości występujące w zbiorze danych"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdTP17X3Spkp"
      },
      "source": [
        "#Trend rosnący"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz7g38DcSjPV"
      },
      "source": [
        "def trend(time, slope=0):\n",
        "    return slope * time\n",
        "\n",
        "time = np.arange(4 * 365 + 1)\n",
        "baseline = 10\n",
        "series = baseline + trend(time, 0.1)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(time, series)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ov-9TAm7Stnk"
      },
      "source": [
        "#Sezonowość"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuTG1g0WBm4c"
      },
      "source": [
        "def seasonal_pattern(season_time):\n",
        "    \"\"\"Just an arbitrary pattern, you can change it if you wish\"\"\"\n",
        "    return np.where(season_time < 0.4,\n",
        "                    np.cos(season_time * 2 * np.pi),\n",
        "                    1 / np.exp(3 * season_time))\n",
        "\n",
        "def seasonality(time, period, amplitude=1, phase=0):\n",
        "    \"\"\"Repeats the same pattern at each period\"\"\"\n",
        "    season_time = ((time + phase) % period) / period\n",
        "    return amplitude * seasonal_pattern(season_time)\n",
        "\n",
        "amplitude = 40\n",
        "series = seasonality(time, period=365, amplitude=amplitude)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(time, series)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoEFur5ES4zz"
      },
      "source": [
        "#Szum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9Xa62cRS1UN"
      },
      "source": [
        "def white_noise(time, noise_level=1, seed=None):\n",
        "    rnd = np.random.RandomState(seed)\n",
        "    return rnd.randn(len(time)) * noise_level\n",
        "\n",
        "noise_level = 5\n",
        "noise = white_noise(time, noise_level, seed=42)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(time, noise)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNnUMaQVS-Oj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4d-JEmQTGdT"
      },
      "source": [
        "#Przewidywanie\n",
        "\n",
        "Posiadając zbiór przedstawiający szereg czasowy pewnych wartości możemy zabrać się za próby oszacowania wartości jakie wystąpią w przyszłości.\n",
        "\n",
        "Użyjemy zbioru przedstawiającego minimalne temperature w Melbourne w latach 1981-1990.\n",
        "\n",
        "Zbiór podzielimy zgodnie z metodą \"Fixed partitioning na część do uczenia, walidacyjną i testującą.\n",
        "\n",
        "#Naiwne przewidywanie\n",
        "\n",
        "Najprostszym możliwym sposobem jest po prostu branie poprzedniej wartości jako przewidywaną. Metoda wydaje się być prymitywna, ale osiągane przez nią rezultaty są warte zaobserwowania chociażby dla celów porównania z innymi metodami.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZfF-wJIVIf4"
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/Mervolt/TimeSeriesTutorial/master/melbourne_min_temp.csv\"\n",
        "\n",
        "dataset = pd.read_csv(url)\n",
        "print(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REIW-UbzVPZt"
      },
      "source": [
        "split = 3000\n",
        "time, values = dataset[\"Date\"], dataset[\"Temp\"]\n",
        "x_train, y_train = time[:split], values[:split]\n",
        "x_valid, y_valid = time[split:], values[split:] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkRIcHeVWH6r"
      },
      "source": [
        "naive_forecast = values[split - 1:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PiHH9BmWLOz"
      },
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(x_valid, y_valid, label=\"Values\")\n",
        "plot_series(x_valid, naive_forecast, label=\"Forecast\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIobBAwyWgPM"
      },
      "source": [
        "Wykresy nachodzą na siebie w takim stopniu, że nie można ich od siebie odróżnić. Wydzielimy teraz dla celów demonstracyjnych podzbiór."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkDMn8WLWqgj"
      },
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(x_valid, y_valid, start=0, end=150, label=\"Values\")\n",
        "plot_series(x_valid, naive_forecast, start=1, end=151, label=\"Forecast\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mw_ZaKp7W9CD"
      },
      "source": [
        "Możemy zaobserwować, że przewidywania są po prostu 1 krok za rzeczywistymi wartościami.\n",
        "\n",
        "W celu ewaluacji potrzebujemy metryk. Użyjemy w tym przypadku metryk średniokwadratowej oraz odległości w przestrzeni Euklidesowej."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW_s6z4FXYEw"
      },
      "source": [
        "print(keras.metrics.mean_absolute_error(y_valid, naive_forecast).numpy())\n",
        "print(keras.metrics.mean_squared_error(y_valid, naive_forecast).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d70EA78STKYR"
      },
      "source": [
        "#Ruchoma średnia\n",
        "Podejściem, które teraz zostanie zaprezentowane to ruchoma średnia. Jest ono relatywnie proste i polega na wyciąganiu średniej z okresu o długości n. To \"ruchome okno\" o długości n przesuwamy po całym zbiorze danych.\n",
        "Przykładowo dla okna o długości, wartość pola o indeksie 7 liczymy jako średnią z pól o indeksach 5, 6 i 7, a dla pola o indeksie 22 z pól o indeksach 20, 21 i 22.\n",
        "\n",
        "Zalety:\n",
        "- redukuje szum\n",
        "\n",
        "Wady:\n",
        "- nie uwzględnia sezonowości\n",
        "- nie uwzględnia trendów"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UT9KI0-aTL2v"
      },
      "source": [
        "def moving_average_forecast(values, window_size):\n",
        "  forecast = []\n",
        "  for time in range(len(values) - window_size):\n",
        "    forecast.append(values[time:time + window_size].mean())\n",
        "  return np.array(forecast)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBUElAeVdNg_"
      },
      "source": [
        "moving_avg = moving_average_forecast(values, 3)[split - 3:]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(x_valid, y_valid, label=\"Values\")\n",
        "plot_series(x_valid, moving_avg, label=\"Ruchoma średnia (3 dni)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vg5wUJEbbg12"
      },
      "source": [
        "print(keras.metrics.mean_absolute_error(y_valid, moving_avg).numpy())\n",
        "print(keras.metrics.mean_squared_error(y_valid, moving_avg).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7gI8Ietfyw6"
      },
      "source": [
        "Szok! Osiągneliśmy gorsze wyniki niż w przypadku naiwnego podejścia. Może długość aplikowanego okna była za mała?\n",
        "Spróbujmy dla innej wielkości okna."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCASOtNmcXKg"
      },
      "source": [
        "moving_avg = moving_average_forecast(values, 10)[split - 10:]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(x_valid, y_valid, label=\"Values\")\n",
        "plot_series(x_valid, moving_avg, label=\"Ruchoma średnia (10 dni)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4F8ObaArgGg_"
      },
      "source": [
        "print(keras.metrics.mean_absolute_error(y_valid, moving_avg).numpy())\n",
        "print(keras.metrics.mean_squared_error(y_valid, moving_avg).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqWNbFrxgIPO"
      },
      "source": [
        "Wciąż gorsze wyniki. Powodem jest tutaj potężna wada tego podejścia, a mianowicie brak uwzględnienia sezonowości, która w przypadku temperatur jest oczywista i bardzo wyraźna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sg4r5f20gYi2"
      },
      "source": [
        "#Ulepszona metoda ruchomej średniej\n",
        "Aby ulepszyć metodę ruchomej średniej należy zlikwidować jej wady - brak uwzględniania trendów oraz brak uwzględniania sezonowości.\n",
        "W tym celu należy specjalnie zadaptować nasz zbiór danych. Zamiast korzystać po prostu z naszego zbioru, korzystać będziemy z różnic (wartość - wartość wcześniejsza o pewien czas t, np. 1 rok i różnica = czerwiec 1984 - czerwiec 1983 )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUsB4HekgHuB"
      },
      "source": [
        "diff_values = (values[365:].reset_index() - values[:-365].reset_index())['Temp']\n",
        "diff_time = time[365:]\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(diff_time, diff_values, label=\"Values(t) – Values(t–365)\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDqrFaumjQWk"
      },
      "source": [
        "Podzbiór walidacyjny"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ6SReKLhNth"
      },
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(x_valid, diff_values[split - 365:], label=\"Values(t) – Values(t–365)\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfT9EhPkjSiP"
      },
      "source": [
        "diff_moving_avg = moving_average_forecast(diff_values, 30)[split - 365 - 30:]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(x_valid, diff_values[split - 365:], label=\"Values(t) – Values(t–365)\")\n",
        "plot_series(x_valid, diff_moving_avg, label=\"Moving Average of Diff\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl-h5dmtjqCW"
      },
      "source": [
        "W porządku. Obliczyliśmy ruchomą średnią, ale nie jest to przecież nasz zbiór danych, a to on jest dla nas interesujący. W takim razie musimy go odzyskać.\n",
        "Aby to zrobić należy dodać wartości z przeszłości."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl-HIllSjgw8"
      },
      "source": [
        "diff_moving_avg_plus_past = values[split - 365:-365] + diff_moving_avg\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(x_valid, y_valid, label=\"Values\")\n",
        "plot_series(x_valid, diff_moving_avg_plus_past, label=\"Forecasts\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKtvMsIskHca"
      },
      "source": [
        "print(keras.metrics.mean_absolute_error(y_valid, diff_moving_avg_plus_past).numpy())\n",
        "print(keras.metrics.mean_squared_error(y_valid, diff_moving_avg_plus_past).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuYag8qeo356"
      },
      "source": [
        "Otrzymaliśmy tragiczne wyniki. Spróbujmy zredukować szum w początkowych danych."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-2MYbE0kLxj"
      },
      "source": [
        "diff_moving_avg_plus_smooth_past = moving_average_forecast(values[split - 370:-359], 11) + diff_moving_avg\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(x_valid, y_valid, label=\"Values\")\n",
        "plot_series(x_valid, diff_moving_avg_plus_smooth_past, label=\"Forecasts\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7hKjnlomei4"
      },
      "source": [
        "print(keras.metrics.mean_absolute_error(y_valid, diff_moving_avg_plus_smooth_past).numpy())\n",
        "print(keras.metrics.mean_squared_error(y_valid, diff_moving_avg_plus_smooth_past).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlW4G2w4o9UD"
      },
      "source": [
        "Znacznie lepiej, jednakże wciąż otrzymaliśmy gorsze rezultaty niż w przypadku naiwnego przewidywania"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAmeQ7hLmqay"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1A99h7mOogMT"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afbM4qu-pUbv"
      },
      "source": [
        "#Przewidywanie - Machine Learning\n",
        "Użyjemy sieci o warstwie 1 bez żadnej funkcji aktywacji. Użyjemy metody regresji."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsaslqBnpX0f"
      },
      "source": [
        "def window_dataset(series, window_size, batch_size=32,\n",
        "                   shuffle_buffer=1000):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(series)\n",
        "    dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
        "    dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
        "    dataset = dataset.shuffle(shuffle_buffer)\n",
        "    dataset = dataset.map(lambda window: (window[:-1], window[-1]))\n",
        "    dataset = dataset.batch(batch_size).prefetch(1)\n",
        "    return dataset\n",
        "\n",
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "window_size = 30\n",
        "train_set = window_dataset(y_train, window_size)\n",
        "valid_set = window_dataset(y_valid, window_size)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "  keras.layers.Dense(1, input_shape=[window_size])\n",
        "])\n",
        "optimizer = keras.optimizers.SGD(lr=1e-5, momentum=0.9)\n",
        "model.compile(loss=keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\", \"mse\"])\n",
        "model.fit(train_set, epochs=100, validation_data=valid_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvEkHTjJreXG"
      },
      "source": [
        "Sukces! Udało nam się przebić naiwne przewidywanie na danych testowych."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYq5Wzmp2D-f"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "window_size = 30\n",
        "train_set = window_dataset(y_train, window_size)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "  keras.layers.Dense(1, input_shape=[window_size])\n",
        "])\n",
        "\n",
        "lr_schedule = keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: 1e-6 * 10**(epoch / 30))\n",
        "optimizer = keras.optimizers.SGD(lr=1e-6, momentum=0.9)\n",
        "model.compile(loss=keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\"])\n",
        "history = model.fit(train_set, epochs=100, callbacks=[lr_schedule])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tICnlx_P2Kf3"
      },
      "source": [
        "plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\n",
        "plt.axis([1e-6, 1e-3, 0, 20])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izJG2aM32Liy"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "window_size = 30\n",
        "train_set = window_dataset(y_train, window_size)\n",
        "valid_set = window_dataset(y_valid, window_size)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "  keras.layers.Dense(1, input_shape=[window_size])\n",
        "])\n",
        "optimizer = keras.optimizers.SGD(lr=1e-5, momentum=0.9)\n",
        "model.compile(loss=keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\", \"mse\"])\n",
        "early_stopping = keras.callbacks.EarlyStopping(patience=10)\n",
        "model.fit(train_set, epochs=500,\n",
        "          validation_data=valid_set,\n",
        "          callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnlBJnsHrjQo"
      },
      "source": [
        "def model_forecast(model, series, window_size):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
        "    ds = ds.window(window_size, shift=1, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda w: w.batch(window_size))\n",
        "    ds = ds.batch(32).prefetch(1)\n",
        "    forecast = model.predict(ds)\n",
        "    return forecast"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1AJZalyr5dk"
      },
      "source": [
        "lin_forecast = model_forecast(model, values[split - window_size:-1], window_size)[:, 0]\n",
        "lin_forecast.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6xGZf3ar_Ua"
      },
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(x_valid, y_valid)\n",
        "plot_series(x_valid, lin_forecast)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO5uXJrtsD30"
      },
      "source": [
        "print(keras.metrics.mean_absolute_error(y_valid, lin_forecast).numpy())\n",
        "print(keras.metrics.mean_squared_error(y_valid, lin_forecast).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meEVAu3UsYRV"
      },
      "source": [
        "Rezultat z dość znaczną poprawą :)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSq1ZG1YqfJq"
      },
      "source": [
        "Dwuwarstwowy model z funkcją aktywacji relu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9M-8HpDqhh8"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "window_size = 30\n",
        "train_set = window_dataset(y_train, window_size)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "  keras.layers.Dense(10, activation=\"relu\", input_shape=[window_size]),\n",
        "  keras.layers.Dense(10, activation=\"relu\"),\n",
        "  keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "lr_schedule = keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: 1e-7 * 10**(epoch / 20))\n",
        "optimizer = keras.optimizers.SGD(lr=1e-7, momentum=0.9)\n",
        "model.compile(loss=keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\", \"mse\"])\n",
        "history = model.fit(train_set, epochs=100, callbacks=[lr_schedule])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yai2QZib2Wnc"
      },
      "source": [
        "plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\n",
        "plt.axis([1e-7, 5e-3, 0, 30])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7KjeqdJ2ZM5"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "window_size = 30\n",
        "train_set = window_dataset(y_train, window_size)\n",
        "valid_set = window_dataset(y_valid, window_size)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "  keras.layers.Dense(10, activation=\"relu\", input_shape=[window_size]),\n",
        "  keras.layers.Dense(10, activation=\"relu\"),\n",
        "  keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "optimizer = keras.optimizers.SGD(lr=1e-5, momentum=0.9)\n",
        "model.compile(loss=keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\", \"mse\"])\n",
        "early_stopping = keras.callbacks.EarlyStopping(patience=10)\n",
        "model.fit(train_set, epochs=500,\n",
        "          validation_data=valid_set,\n",
        "          callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRvrbtA8sgEB"
      },
      "source": [
        "dense_forecast = model_forecast(\n",
        "    model,\n",
        "    values[split - window_size:-1],\n",
        "    window_size)[:, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9_LfmrNtM3T"
      },
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(x_valid, y_valid)\n",
        "plot_series(x_valid, dense_forecast)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpUD0hm5tV9u"
      },
      "source": [
        "print(keras.metrics.mean_absolute_error(y_valid, dense_forecast).numpy())\n",
        "print(keras.metrics.mean_squared_error(y_valid, dense_forecast).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi-OZzyCtW9f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh-835UCtig0"
      },
      "source": [
        "#RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DppNPs5wtjjJ"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "window_size = 30\n",
        "train_set = window_dataset(y_train, window_size, batch_size=128)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "  keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
        "                      input_shape=[None]),\n",
        "  keras.layers.SimpleRNN(100, return_sequences=True),\n",
        "  keras.layers.SimpleRNN(100),\n",
        "  keras.layers.Dense(1),\n",
        "  keras.layers.Lambda(lambda x: x * 200.0)\n",
        "])\n",
        "lr_schedule = keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: 1e-7 * 10**(epoch / 20))\n",
        "optimizer = keras.optimizers.SGD(lr=1e-7, momentum=0.9)\n",
        "model.compile(loss=keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\", \"mse\"])\n",
        "history = model.fit(train_set, epochs=100, callbacks=[lr_schedule])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7JgcUEJtqMQ"
      },
      "source": [
        "plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\n",
        "plt.axis([1e-7, 1e-4, 0, 30])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8_f4aQit3YZ"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "window_size = 30\n",
        "train_set = window_dataset(y_train, window_size, batch_size=128)\n",
        "valid_set = window_dataset(y_valid, window_size, batch_size=128)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "  keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=-1),\n",
        "                      input_shape=[None]),\n",
        "  keras.layers.SimpleRNN(100, return_sequences=True),\n",
        "  keras.layers.SimpleRNN(100),\n",
        "  keras.layers.Dense(1),\n",
        "  keras.layers.Lambda(lambda x: x * 200.0)\n",
        "])\n",
        "optimizer = keras.optimizers.SGD(lr=1.5e-6, momentum=0.9)\n",
        "model.compile(loss=keras.losses.Huber(),\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"mae\"])\n",
        "early_stopping = keras.callbacks.EarlyStopping(patience=50)\n",
        "model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "    \"my_checkpoint\", save_best_only=True)\n",
        "model.fit(train_set, epochs=500,\n",
        "          validation_data=valid_set,\n",
        "          callbacks=[early_stopping, model_checkpoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sByrEOht9J7"
      },
      "source": [
        "rnn_forecast = model_forecast(\n",
        "    model,\n",
        "    values[split - window_size:-1],\n",
        "    window_size)[:, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TmESZVPt9_c"
      },
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plot_series(x_valid, y_valid)\n",
        "plot_series(x_valid, rnn_forecast)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFncvCV6uAlZ"
      },
      "source": [
        "print(keras.metrics.mean_absolute_error(y_valid, rnn_forecast).numpy())\n",
        "print(keras.metrics.mean_squared_error(y_valid, rnn_forecast).numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdYWD50uyaFT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}